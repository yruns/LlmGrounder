{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-07-31T11:48:36.516041Z",
     "start_time": "2024-07-31T11:48:35.823309Z"
    }
   },
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"false\"\n",
    "os.environ[\"LANGSMITH_API_KEY\"] = \"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\"\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"sk-c1h5RWNyx6WxgiNEF2D01f2cF1A042De95F94b6b3b0cB5C3\"\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "model = ChatOpenAI(model=\"gpt-4o\", base_url=\"https://api3.wlai.vip/v1/\")"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-31T11:48:37.588658Z",
     "start_time": "2024-07-31T11:48:37.584191Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import base64\n",
    "\n",
    "def encode_image_to_base64(image_path):\n",
    "    with open(image_path, \"rb\") as image_file:\n",
    "        return base64.b64encode(image_file.read()).decode('utf-8')"
   ],
   "id": "d8c05806a2dd60ca",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-31T11:48:39.213346Z",
     "start_time": "2024-07-31T11:48:39.204319Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from typing import List, Optional\n",
    "\n",
    "from langchain_core.output_parsers import PydanticOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field, validator\n",
    "\n",
    "\n",
    "class Result(BaseModel):\n",
    "    \"\"\"\n",
    "    The result of the image locator.\n",
    "    \"\"\"\n",
    "    index: int= Field(\n",
    "        default=None, \n",
    "        description=\"the index of the upper-left corner of the bbox\")\n",
    "    \n",
    "    reason: str = Field(\n",
    "        default=None,\n",
    "        description=\"the reason why the index is chosen\"\n",
    "    )\n",
    "\n",
    "# Set up a parser\n",
    "parser = PydanticOutputParser(pydantic_object=Result)"
   ],
   "id": "c4da4961ed83e1",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-31T11:48:39.939392Z",
     "start_time": "2024-07-31T11:48:39.851493Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "system_instruction = \"\"\"You are a helpful image locator who can understand the text descriptions I give you about a specific object. You need to answer which bounding box (bbox) in the image contains the target object from the text description. You only need to provide the index of the upper-left corner of the bbox and explain why you chose it. \"Wrap the output in `json` tags\\n{format_instructions}\"\n",
    "\"\"\"\n",
    "description = \"if you are facing the three windows on one wall it is the window on the left.\"\n",
    "\n",
    "content = [{\"type\": \"text\", \"text\": description}]\n",
    "for i in range(2):\n",
    "    content.append({\"type\": \"image_url\", \"image_url\": {\n",
    "        \"url\": f\"data:image/png;base64,{encode_image_to_base64(f'view_{i}.png')}\"\n",
    "    }})\n",
    "\n",
    "message = [\n",
    "    (\"system\", system_instruction),\n",
    "    HumanMessage(content=content)\n",
    "]\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(message).partial(format_instructions=parser.get_format_instructions())\n",
    "# prompt.invoke({})"
   ],
   "id": "9d571a06847e2e36",
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'view_0.png'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mFileNotFoundError\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[4], line 10\u001B[0m\n\u001B[1;32m      7\u001B[0m content \u001B[38;5;241m=\u001B[39m [{\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtype\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtext\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtext\u001B[39m\u001B[38;5;124m\"\u001B[39m: description}]\n\u001B[1;32m      8\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;241m2\u001B[39m):\n\u001B[1;32m      9\u001B[0m     content\u001B[38;5;241m.\u001B[39mappend({\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtype\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mimage_url\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mimage_url\u001B[39m\u001B[38;5;124m\"\u001B[39m: {\n\u001B[0;32m---> 10\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124murl\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdata:image/png;base64,\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mencode_image_to_base64(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mview_\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mi\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m.png\u001B[39m\u001B[38;5;124m'\u001B[39m)\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m     11\u001B[0m     }})\n\u001B[1;32m     13\u001B[0m message \u001B[38;5;241m=\u001B[39m [\n\u001B[1;32m     14\u001B[0m     (\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124msystem\u001B[39m\u001B[38;5;124m\"\u001B[39m, system_instruction),\n\u001B[1;32m     15\u001B[0m     HumanMessage(content\u001B[38;5;241m=\u001B[39mcontent)\n\u001B[1;32m     16\u001B[0m ]\n\u001B[1;32m     18\u001B[0m prompt \u001B[38;5;241m=\u001B[39m ChatPromptTemplate\u001B[38;5;241m.\u001B[39mfrom_messages(message)\u001B[38;5;241m.\u001B[39mpartial(format_instructions\u001B[38;5;241m=\u001B[39mparser\u001B[38;5;241m.\u001B[39mget_format_instructions())\n",
      "Cell \u001B[0;32mIn[2], line 4\u001B[0m, in \u001B[0;36mencode_image_to_base64\u001B[0;34m(image_path)\u001B[0m\n\u001B[1;32m      3\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mencode_image_to_base64\u001B[39m(image_path):\n\u001B[0;32m----> 4\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28;43mopen\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mimage_path\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mrb\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m \u001B[38;5;28;01mas\u001B[39;00m image_file:\n\u001B[1;32m      5\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m base64\u001B[38;5;241m.\u001B[39mb64encode(image_file\u001B[38;5;241m.\u001B[39mread())\u001B[38;5;241m.\u001B[39mdecode(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mutf-8\u001B[39m\u001B[38;5;124m'\u001B[39m)\n",
      "File \u001B[0;32m~/anaconda3/envs/lmmgrounder/lib/python3.8/site-packages/IPython/core/interactiveshell.py:284\u001B[0m, in \u001B[0;36m_modified_open\u001B[0;34m(file, *args, **kwargs)\u001B[0m\n\u001B[1;32m    277\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m file \u001B[38;5;129;01min\u001B[39;00m {\u001B[38;5;241m0\u001B[39m, \u001B[38;5;241m1\u001B[39m, \u001B[38;5;241m2\u001B[39m}:\n\u001B[1;32m    278\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[1;32m    279\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mIPython won\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mt let you open fd=\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mfile\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m by default \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    280\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    281\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124myou can use builtins\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m open.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    282\u001B[0m     )\n\u001B[0;32m--> 284\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mio_open\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfile\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[0;31mFileNotFoundError\u001B[0m: [Errno 2] No such file or directory: 'view_0.png'"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-31T11:48:57.757648Z",
     "start_time": "2024-07-31T11:48:57.729900Z"
    }
   },
   "cell_type": "code",
   "source": [
    "chain = prompt | model | parser\n",
    "result = chain.invoke({})\n",
    "print(type(result))\n",
    "print(\"result\", result)"
   ],
   "id": "c2438ec1170b550a",
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'prompt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[7], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m chain \u001B[38;5;241m=\u001B[39m \u001B[43mprompt\u001B[49m \u001B[38;5;241m|\u001B[39m model \u001B[38;5;241m|\u001B[39m parser\n\u001B[1;32m      2\u001B[0m result \u001B[38;5;241m=\u001B[39m chain\u001B[38;5;241m.\u001B[39minvoke({})\n\u001B[1;32m      3\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;28mtype\u001B[39m(result))\n",
      "\u001B[0;31mNameError\u001B[0m: name 'prompt' is not defined"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-31T11:48:43.376024Z",
     "start_time": "2024-07-31T11:48:42.187325Z"
    }
   },
   "cell_type": "code",
   "source": "model.invoke(\"hello\")",
   "id": "2f03895327de17ee",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Hello! How can I assist you today?', response_metadata={'token_usage': {'completion_tokens': 9, 'prompt_tokens': 8, 'total_tokens': 17}, 'model_name': 'gpt-4o-2024-05-13', 'system_fingerprint': 'fp_abc28019ad', 'finish_reason': 'stop', 'logprobs': None}, id='run-0350e9db-9db8-4776-9da8-2850e7e9121f-0', usage_metadata={'input_tokens': 8, 'output_tokens': 9, 'total_tokens': 17})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "514b35f209962deb"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
