{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-07-31T08:44:16.672944Z",
     "start_time": "2024-07-31T08:44:05.156001Z"
    }
   },
   "source": [
    "from langchain_ollama.llms import OllamaLLM\n",
    "\n",
    "llm = OllamaLLM(model=\"llava:34b\")\n",
    "\n",
    "# warmup\n",
    "llm.invoke(\"hello\")"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Hello! How can I assist you today? üòÑ If there's anything specific you would like to know or talk about, feel free to let me know. Just type your message below and I will respond as soon as possible.\\n\\nRemember, I am a learning model so please be patient with my responses and don't hesitate to ask for clarification if needed. I'm always happy to help! ü§ñ\\n\\nAlso, it would be great if you could provide me feedback on how I'm doing by clicking one of the smiley faces below:\\n\\n[üòä] [üòï] [üòí] [üò†] [üëç] [üëé] [üö´] [ü§î] [üòÖ] [üò¥]\\n\\nPlease note that any feedback you provide will help me improve and serve better. Thank you! üôè\""
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-31T08:46:41.019841Z",
     "start_time": "2024-07-31T08:46:40.991936Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import base64\n",
    "from io import BytesIO\n",
    "\n",
    "from IPython.display import HTML, display\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "def convert_to_base64(pil_image):\n",
    "    \"\"\"\n",
    "    Convert PIL images to Base64 encoded strings\n",
    "\n",
    "    :param pil_image: PIL image\n",
    "    :return: Re-sized Base64 string\n",
    "    \"\"\"\n",
    "\n",
    "    buffered = BytesIO()\n",
    "    pil_image.save(buffered, format=\"PNG\")  # You can change the format if needed\n",
    "    img_str = base64.b64encode(buffered.getvalue()).decode(\"utf-8\")\n",
    "    return img_str\n",
    "\n",
    "\n",
    "def plt_img_base64(img_base64):\n",
    "    \"\"\"\n",
    "    Display base64 encoded string as image\n",
    "\n",
    "    :param img_base64:  Base64 string\n",
    "    \"\"\"\n",
    "    # Create an HTML img tag with the base64 string as the source\n",
    "    image_html = f'<img src=\"data:image/png;base64,{img_base64}\" />'\n",
    "    # Display the image by rendering the HTML\n",
    "    display(HTML(image_html))\n",
    "    \n",
    "image_root = \"../rendered_views/scene0704_00/1618/high/\"\n",
    "\n",
    "def encode_image_to_base64(image_path):\n",
    "    with open(image_path, \"rb\") as image_file:\n",
    "        return base64.b64encode(image_file.read()).decode('utf-8')\n",
    "\n",
    "images = []\n",
    "for i in range(4):\n",
    "    # pil_image = Image.open(image_root + f\"view_{i}.png\")\n",
    "    # image_base64 = convert_to_base64(pil_image)\n",
    "    images.append(encode_image_to_base64(image_root + f\"view_{i}.png\"))\n",
    "    # plt_img_base64(image_base64)"
   ],
   "id": "ad42c46219c48b96",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-31T08:46:42.416642Z",
     "start_time": "2024-07-31T08:46:42.408994Z"
    }
   },
   "cell_type": "code",
   "source": "llm_with_image_context = llm.bind(images=images)",
   "id": "c1cdeea9231acfa1",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-31T08:46:46.747834Z",
     "start_time": "2024-07-31T08:46:46.454081Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import base64\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.output_parsers import PydanticOutputParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "\n",
    "class Result(BaseModel):\n",
    "    \"\"\"\n",
    "    The result of the image locator.\n",
    "    \"\"\"\n",
    "    index: int = Field(\n",
    "        default=None, \n",
    "        enum=[0, 1],\n",
    "        description=\"the index of the upper-left corner of the bbox\")\n",
    "\n",
    "    reason: str = Field(\n",
    "        default=None,\n",
    "        description=\"the reason why the index is chosen\"\n",
    "    )\n",
    "    \n",
    "parser = PydanticOutputParser(pydantic_object=Result)\n",
    "template = \"\"\"You are a helpful image locator who can understand the text description I give you about a specific object. You need to answer which bounding box (bbox) in the image contains the target object from the text description. You only need to provide the index of the upper-left corner of the bbox and explain why you chose it. Wrap the output in `json` tags\\n{format_instructions} \\ndescription: {description}\n",
    "\"\"\"\n",
    "\n",
    "description = \"looking in from the door the trash can on the right\"\n",
    "\n",
    "prompt = PromptTemplate.from_template(template).partial(format_instructions=parser.get_format_instructions())\n",
    "# print(prompt.format_prompt(description=description).to_string())\n",
    "prompt.invoke({\"description\": description})"
   ],
   "id": "6a4230ed3244c369",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StringPromptValue(text='You are a helpful image locator who can understand the text description I give you about a specific object. You need to answer which bounding box (bbox) in the image contains the target object from the text description. You only need to provide the index of the upper-left corner of the bbox and explain why you chose it. Wrap the output in `json` tags\\nThe output should be formatted as a JSON instance that conforms to the JSON schema below.\\n\\nAs an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}\\nthe object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\\n\\nHere is the output schema:\\n```\\n{\"description\": \"The result of the image locator.\", \"properties\": {\"index\": {\"title\": \"Index\", \"description\": \"the index of the upper-left corner of the bbox\", \"enum\": [0, 1], \"type\": \"integer\"}, \"reason\": {\"title\": \"Reason\", \"description\": \"the reason why the index is chosen\", \"type\": \"string\"}}}\\n``` \\ndescription: looking in from the door the trash can on the right\\n')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-31T08:47:08.574647Z",
     "start_time": "2024-07-31T08:46:48.814626Z"
    }
   },
   "cell_type": "code",
   "source": [
    "chain = prompt | llm_with_image_context | parser\n",
    "\n",
    "for i in range(10):\n",
    "    print(f\"Attempt {i}:\", end=\" \")\n",
    "    try:\n",
    "        print(chain.invoke({\"description\": description}))\n",
    "    except:\n",
    "        print(\"Error ocurred\")\n",
    "        pass"
   ],
   "id": "9b2066cb3cace308",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempt 0: index=0 reason=\"The bounding box at index 0 contains the trash can to the right of the entrance. This matches the description provided: 'looking in from the door the trash can on the right'.\"\n",
      "Attempt 1: index=1 reason=\"The image contains a trash can located on the right side. Based on your text description 'looking in from the door', we are assuming that you are looking at the image from the direction of the entrance or exit of a building, such as a house or an office. This would place the 'door' on the left side of the image, and consequently, the trash can would be located on the right side. Therefore, bbox 1, which is positioned on the right side of the image, contains the trash can.\"\n",
      "Attempt 2: index=1 reason='The trash can is located to the right of the doorway and slightly ahead of it. The bounding box at index 1 includes the trash can.'\n",
      "Attempt 3: index=1 reason='The bbox with index 1 contains a trash can which is described as being on the right and located in from of the door. The other bbox does not contain any objects matching this description.'\n",
      "Attempt 4: index=0 reason='The image description refers to a trash can on the right. Based on this information, I have chosen bbox with index 0 because it is located on the right side of the door and matches the description given in the text.'\n",
      "Attempt 5: index=1 reason='The trash can is located towards the right of the image and slightly in the back. Since we are looking from the door, the trash can would be on our right side. Therefore, index 1 represents the upper-left corner of the bbox containing the target object.'\n",
      "Attempt 6: index=0 reason='The trash can is on the right side of the image. The bounding box at index 0 starts at the upper-left corner of the image and includes the right side where the trash can is located.'\n",
      "Attempt 7: index=1 reason='The image shows a trash can to the right of the door. The bounding box with index 1 covers the trash can and is therefore the correct choice.'\n",
      "Attempt 8: index=1 reason=\"The image shows a scene with two objects. The object that corresponds to 'looking in from the door the trash can on the right' is the trash can located at the right side of the image. Therefore, I chose the index 1 for the bbox corresponding to the trash can.\"\n",
      "Attempt 9: index=1 reason='The trash can is located on the right side of the image, which corresponds to bounding box number 1. Looking in from the door, this bbox is where you would expect to see the trash can.'\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-30T16:14:57.609814Z",
     "start_time": "2024-07-30T16:14:57.606002Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "aa3f9c252705726c",
   "outputs": [],
   "execution_count": 6
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
