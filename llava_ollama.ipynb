{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-07-31T04:28:43.254228Z",
     "start_time": "2024-07-31T04:28:41.653758Z"
    }
   },
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_ollama.llms import OllamaLLM\n",
    "\n",
    "llm = OllamaLLM(model=\"llava:34b\")\n",
    "\n",
    "# warmup\n",
    "llm.invoke(\"hello\")"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Hi there, I'm a chatbot and I'm here to help! What is on your mind?\""
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-31T05:08:34.163811Z",
     "start_time": "2024-07-31T05:08:32.043488Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import base64\n",
    "from io import BytesIO\n",
    "\n",
    "from IPython.display import HTML, display\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "def convert_to_base64(pil_image):\n",
    "    \"\"\"\n",
    "    Convert PIL images to Base64 encoded strings\n",
    "\n",
    "    :param pil_image: PIL image\n",
    "    :return: Re-sized Base64 string\n",
    "    \"\"\"\n",
    "\n",
    "    buffered = BytesIO()\n",
    "    pil_image.save(buffered, format=\"PNG\")  # You can change the format if needed\n",
    "    img_str = base64.b64encode(buffered.getvalue()).decode(\"utf-8\")\n",
    "    return img_str\n",
    "\n",
    "\n",
    "def plt_img_base64(img_base64):\n",
    "    \"\"\"\n",
    "    Display base64 encoded string as image\n",
    "\n",
    "    :param img_base64:  Base64 string\n",
    "    \"\"\"\n",
    "    # Create an HTML img tag with the base64 string as the source\n",
    "    image_html = f'<img src=\"data:image/png;base64,{img_base64}\" />'\n",
    "    # Display the image by rendering the HTML\n",
    "    display(HTML(image_html))\n",
    "    \n",
    "image_root = \"base_grounder/rendered_views/scene0704_00/1618/high/\"\n",
    "\n",
    "images = []\n",
    "for i in range(4):\n",
    "    pil_image = Image.open(image_root + f\"view_{i}.png\")\n",
    "    image_base64 = convert_to_base64(pil_image)\n",
    "    images.append(image_base64)\n",
    "    # plt_img_base64(image_base64)"
   ],
   "id": "ad42c46219c48b96",
   "outputs": [],
   "execution_count": 31
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-31T05:08:35.732746Z",
     "start_time": "2024-07-31T05:08:35.725149Z"
    }
   },
   "cell_type": "code",
   "source": "llm_with_image_context = llm.bind(images=images)",
   "id": "c1cdeea9231acfa1",
   "outputs": [],
   "execution_count": 32
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-31T05:08:36.934904Z",
     "start_time": "2024-07-31T05:08:36.918772Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import base64\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.output_parsers import PydanticOutputParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "\n",
    "class Result(BaseModel):\n",
    "    \"\"\"\n",
    "    The result of the image locator.\n",
    "    \"\"\"\n",
    "    index: int = Field(\n",
    "        default=None, \n",
    "        enum=[0, 1],\n",
    "        description=\"the index of the upper-left corner of the bbox\")\n",
    "\n",
    "    reason: str = Field(\n",
    "        default=None,\n",
    "        description=\"the reason why the index is chosen\"\n",
    "    )\n",
    "    \n",
    "parser = PydanticOutputParser(pydantic_object=Result)\n",
    "template = \"\"\"You are a helpful image locator who can understand the text description I give you about a specific object. You need to answer which bounding box (bbox) in the image contains the target object from the text description. You only need to provide the index of the upper-left corner of the bbox and explain why you chose it. Wrap the output in `json` tags\\n{format_instructions} \\ndescription: {description}\n",
    "\"\"\"\n",
    "\n",
    "description = \"looking in from the door the trash can on the right\"\n",
    "\n",
    "prompt = PromptTemplate.from_template(template).partial(format_instructions=parser.get_format_instructions())\n",
    "# print(prompt.format_prompt(description=description).to_string())\n",
    "prompt.invoke({\"description\": description})"
   ],
   "id": "6a4230ed3244c369",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StringPromptValue(text='You are a helpful image locator who can understand the text description I give you about a specific object. You need to answer which bounding box (bbox) in the image contains the target object from the text description. You only need to provide the index of the upper-left corner of the bbox and explain why you chose it. Wrap the output in `json` tags\\nThe output should be formatted as a JSON instance that conforms to the JSON schema below.\\n\\nAs an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}\\nthe object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\\n\\nHere is the output schema:\\n```\\n{\"description\": \"The result of the image locator.\", \"properties\": {\"index\": {\"title\": \"Index\", \"description\": \"the index of the upper-left corner of the bbox\", \"enum\": [0, 1], \"type\": \"integer\"}, \"reason\": {\"title\": \"Reason\", \"description\": \"the reason why the index is chosen\", \"type\": \"string\"}}}\\n``` \\ndescription: looking in from the door the trash can on the right\\n')"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 33
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-31T05:09:21.171671Z",
     "start_time": "2024-07-31T05:08:52.755999Z"
    }
   },
   "cell_type": "code",
   "source": [
    "chain = prompt | llm_with_image_context | parser\n",
    "\n",
    "for i in range(10):\n",
    "    print(f\"Attempt {i}:\", end=\" \")\n",
    "    try:\n",
    "        print(chain.invoke({\"description\": description}))\n",
    "    except:\n",
    "        print(\"Error ocurred\")\n",
    "        pass"
   ],
   "id": "9b2066cb3cace308",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempt 0: index=0 reason='The trash can is located on the right side of the image. The index 0 corresponds to the bounding box that includes the door and the area where you would be looking from when viewing the trash can. This matches the text description provided.'\n",
      "Attempt 1: index=1 reason=\"The reason is that the image contains two bounding boxes (bbox) and the trash can is located to the right. The left bbox corresponds to index 0 while the right one corresponds to index 1. Therefore, I choose the right bbox as it matches the description of the object's location.\"\n",
      "Attempt 2: index=1 reason=\"The trash can is located to the right of the door frame. It appears as a large object with a cylindrical shape typical of trash cans, and it's clearly distinguishable from the other objects in the image. Therefore, I chose the bbox with index 1 to represent the trash can.\"\n",
      "Attempt 3: index=0 reason='The trash can is located to the right of a door, and it appears to be closer than other objects in the image. Therefore, we choose the first bounding box (bbox) with index 0 which contains the target object based on this text description.'\n",
      "Attempt 4: index=1 reason='The trash can is located on the right side of the image, as described from looking in from the door.'\n",
      "Attempt 5: index=1 reason='The trash can is located on the right side of the room as viewed from the doorway, matching the text description.'\n",
      "Attempt 6: index=1 reason=\"The trash can is located on the right side of the image, and when viewed from the door perspective, it's more to the right. Therefore, the index of the upper-left corner of the bbox with the trash can in it corresponds to the second bbox.\"\n",
      "Attempt 7: index=1 reason=\"The trash can is on the right side of the image and it's located close to the doorway.\"\n",
      "Attempt 8: index=1 reason='The trash can is located on the right side of the image, as seen from the doorway. The bounding box with index 1 encompasses the area where the trash can is present.'\n",
      "Attempt 9: index=0 reason='The trash can on the right is visible when you look into the room from the door, and it is located on the left side of the image. The bounding box at index 1 contains the trash can but only if viewed from a different angle than described in the text.'\n"
     ]
    }
   ],
   "execution_count": 34
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-30T16:14:57.609814Z",
     "start_time": "2024-07-30T16:14:57.606002Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "aa3f9c252705726c",
   "outputs": [],
   "execution_count": 6
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
