{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-07-29T07:19:20.046976Z",
     "start_time": "2024-07-29T07:19:19.204785Z"
    }
   },
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"false\"\n",
    "os.environ[\"LANGSMITH_API_KEY\"] = \"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\"\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"sk-c1h5RWNyx6WxgiNEF2D01f2cF1A042De95F94b6b3b0cB5C3\"\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "model = ChatOpenAI(model=\"gpt-4o\", base_url=\"https://api3.wlai.vip/v1/\")"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T07:19:20.876341Z",
     "start_time": "2024-07-29T07:19:20.867537Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import base64\n",
    "\n",
    "def encode_image_to_base64(image_path):\n",
    "    with open(image_path, \"rb\") as image_file:\n",
    "        return base64.b64encode(image_file.read()).decode('utf-8')"
   ],
   "id": "d8c05806a2dd60ca",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T07:19:21.449603Z",
     "start_time": "2024-07-29T07:19:21.438794Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from typing import List, Optional\n",
    "\n",
    "from langchain_core.output_parsers import PydanticOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field, validator\n",
    "\n",
    "\n",
    "class Result(BaseModel):\n",
    "    \"\"\"\n",
    "    The result of the image locator.\n",
    "    \"\"\"\n",
    "    index: int= Field(\n",
    "        default=None, \n",
    "        description=\"the index of the upper-left corner of the bbox\")\n",
    "    \n",
    "    reason: str = Field(\n",
    "        default=None,\n",
    "        description=\"the reason why the index is chosen\"\n",
    "    )\n",
    "\n",
    "# Set up a parser\n",
    "parser = PydanticOutputParser(pydantic_object=Result)"
   ],
   "id": "c4da4961ed83e1",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T07:19:22.143906Z",
     "start_time": "2024-07-29T07:19:22.123245Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "system_instruction = \"\"\"You are a helpful image locator who can understand the text descriptions I give you about a specific object. You need to answer which bounding box (bbox) in the image contains the target object from the text description. You only need to provide the index of the upper-left corner of the bbox and explain why you chose it. \"Wrap the output in `json` tags\\n{format_instructions}\"\n",
    "\"\"\"\n",
    "description = \"if you are facing the three windows on one wall it is the window on the left.\"\n",
    "\n",
    "content = [{\"type\": \"text\", \"text\": description}]\n",
    "for i in range(2):\n",
    "    content.append({\"type\": \"image_url\", \"image_url\": {\n",
    "        \"url\": f\"data:image/png;base64,{encode_image_to_base64(f'view_{i}.png')}\"\n",
    "    }})\n",
    "\n",
    "message = [\n",
    "    (\"system\", system_instruction),\n",
    "    HumanMessage(content=content)\n",
    "]\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(message).partial(format_instructions=parser.get_format_instructions())\n",
    "# prompt.invoke({})"
   ],
   "id": "9d571a06847e2e36",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T07:28:36.640395Z",
     "start_time": "2024-07-29T07:22:45.385268Z"
    }
   },
   "cell_type": "code",
   "source": [
    "chain = prompt | model | parser\n",
    "result = chain.invoke({})\n",
    "print(type(result))\n",
    "print(result)"
   ],
   "id": "c2438ec1170b550a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class '__main__.Result'>\n",
      "index=6 reason='The window on the left when facing the three windows on one wall is indicated by bounding box 6 in both images.'\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "2f03895327de17ee"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
